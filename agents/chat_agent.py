import asyncio
import logging
import os
import re
import json
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, Optional, List
from uuid import uuid4
from pathlib import Path

from dotenv import load_dotenv
from sqlalchemy.orm import Session
from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import START, MessagesState, StateGraph
from langgraph.checkpoint.memory import MemorySaver

from schemas import ChatRequest
from models import Conversation, Message, User

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# --- Carregar Base de Conhecimento de UI ---
UI_KNOWLEDGE_PATH = Path(__file__).parent.parent / "data" / "docs" / "ui_descriptions.json"

def _load_ui_knowledge() -> Dict:
    """Carrega base de conhecimento de UI."""
    try:
        if UI_KNOWLEDGE_PATH.exists():
            with open(UI_KNOWLEDGE_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        logging.warning(f"Falha ao carregar UI knowledge: {e}")
    return {"routes": {}, "common_flows": {}, "glossary": {}}

UI_KNOWLEDGE = _load_ui_knowledge()

# --- Mapeamento de Rotas da Aplica√ß√£o ---
ROUTE_MAPPING = {
    "/": "p√°gina inicial",
    "/dashboard": """
**Dashboard** - Vis√£o geral do neg√≥cio
- M√©tricas principais (KPIs)
- Resumo de ordens de servi√ßo
- Faturamento do per√≠odo
- Gr√°ficos de desempenho
- Alertas e notifica√ß√µes importantes
""",
    "/service-orders": """
**Ordens de Servi√ßo** - Controle de OS
- Criar nova ordem de servi√ßo
- Listar ordens (abertas, em andamento, conclu√≠das)
- Filtrar por status, cliente, ve√≠culo, t√©cnico
- Visualizar detalhes e hist√≥rico
- Imprimir ordens
- Adicionar pe√ßas e servi√ßos
""",
    "/inventory": """
**Estoque/Invent√°rio** - Gest√£o de Pe√ßas
- Visualizar itens em estoque
- Movimenta√ß√µes (entrada/sa√≠da)
- Alertas de estoque m√≠nimo
- Hist√≥rico de movimenta√ß√£o
- Reserva de pe√ßas para OS
- Relat√≥rios de giro de estoque
""",
    "/clients": """
**Clientes** - Gest√£o de Clientes
- Cadastrar novo cliente
- Listar e buscar clientes
- Editar informa√ß√µes
- Visualizar hist√≥rico de servi√ßos
- Ver ve√≠culos do cliente
- Exportar dados
""",
    "/vehicles": """
**Ve√≠culos** - Cadastro e Hist√≥rico
- Cadastrar novo ve√≠culo
- Vincular a cliente
- Hist√≥rico de manuten√ß√µes
- Quilometragem atual
- Detalhes t√©cnicos (marca, modelo, ano)
- Revis√µes programadas
""",
    "/parts": """
**Pe√ßas** - Cat√°logo de Pe√ßas
- Cadastrar nova pe√ßa
- Gerenciar cat√°logo
- Definir pre√ßos e custos
- Markup e margem
- SKU e c√≥digo de barras
- Fornecedores
""",
    "/users": """
**Usu√°rios** - Gest√£o de Equipe
- Cadastrar usu√°rios
- Definir permiss√µes e cargos
- Gerenciar acesso
- Visualizar atividades
""",
    "/analytics": """
**An√°lises** - Relat√≥rios e Estat√≠sticas
- Relat√≥rios financeiros
- Desempenho de t√©cnicos
- An√°lise de vendas
- Gr√°ficos personalizados
- Exportar relat√≥rios
""",
}

# --- Mini-Gloss√°rio de Termos do Sistema ---
GLOSSARY = {
    "OS": "Ordem de Servi√ßo - Documento que registra um servi√ßo a ser executado em um ve√≠culo",
    "ordem de servi√ßo": "Documento que registra um servi√ßo a ser executado em um ve√≠culo, incluindo descri√ß√£o do problema, diagn√≥stico, pe√ßas utilizadas e custos",
    "markup": "Percentual adicionado ao custo de uma pe√ßa para definir o pre√ßo de venda. Exemplo: custo R$100 + markup 50% = pre√ßo R$150",
    "revis√£o programada": "Manuten√ß√£o preventiva agendada com base na quilometragem ou tempo desde a √∫ltima revis√£o",
    "NPS": "Net Promoter Score - M√©trica de satisfa√ß√£o do cliente (escala de 0 a 10)",
    "margem": "Diferen√ßa entre o pre√ßo de venda e o custo, geralmente expressa em percentual",
    "giro de estoque": "Frequ√™ncia com que o estoque √© renovado em um per√≠odo (quantas vezes foi vendido e reposto)",
    "SKU": "Stock Keeping Unit - C√≥digo √∫nico para identificar cada produto/pe√ßa no sistema",
    "invent√°rio": "Conjunto de todas as pe√ßas e produtos em estoque na oficina",
    "estoque m√≠nimo": "Quantidade m√≠nima que deve ser mantida em estoque antes de fazer nova compra",
    "movimenta√ß√£o": "Entrada ou sa√≠da de pe√ßas do estoque (compra, venda, transfer√™ncia, ajuste)",
    "KPI": "Key Performance Indicator - Indicadores chave de desempenho do neg√≥cio",
    "LGPD": "Lei Geral de Prote√ß√£o de Dados - Legisla√ß√£o brasileira sobre privacidade e prote√ß√£o de dados pessoais",
    "auditoria": "Registro de todas as altera√ß√µes feitas no sistema, incluindo quem fez, quando e o que foi modificado",
    "multi-tenancy": "Arquitetura que permite m√∫ltiplas oficinas (organiza√ß√µes) usarem o mesmo sistema de forma isolada",
}

# --- System Prompt com Personalidade ---
SYSTEM_PROMPT = """Voc√™ √© o assistente virtual do GoMech, um sistema inteligente de gest√£o para oficinas mec√¢nicas. 

üéØ **SUA PERSONALIDADE:**
- Seja amig√°vel, prestativo e profissional
- Use linguagem clara e acess√≠vel
- Seja proativo em oferecer ajuda
- Mantenha o contexto da conversa
- Use emojis ocasionalmente para ser mais amig√°vel üòä
- Trate o usu√°rio de forma respeitosa (voc√™)

üîß **SUAS CAPACIDADES:**
1. **Consultar dados do sistema** - clientes, ve√≠culos, ordens de servi√ßo, estoque, pe√ßas
2. **Gerar gr√°ficos e visualiza√ß√µes** - estat√≠sticas e relat√≥rios visuais
3. **Buscar v√≠deos tutoriais** - conte√∫do educativo sobre mec√¢nica
4. **Explicar funcionalidades** - como usar o sistema e suas p√°ginas
5. **Dar suporte** - tirar d√∫vidas e orientar sobre processos

üìö **GLOSS√ÅRIO DE TERMOS:**
Voc√™ conhece estes termos do sistema GoMech:
- **OS/Ordem de Servi√ßo**: Documento de registro de servi√ßo
- **Markup**: Percentual adicionado ao custo para formar o pre√ßo
- **Revis√£o Programada**: Manuten√ß√£o preventiva agendada
- **Giro de Estoque**: Frequ√™ncia de renova√ß√£o do estoque
- **SKU**: C√≥digo √∫nico de produto
- **KPI**: Indicador chave de desempenho
- **LGPD**: Lei de prote√ß√£o de dados
- **Multi-tenancy**: M√∫ltiplas oficinas no mesmo sistema

Se o usu√°rio perguntar sobre algum termo, explique de forma clara e did√°tica.

üí° **DICAS PARA SUAS RESPOSTAS:**
- Se o usu√°rio perguntar sobre dados, sugira que pode buscar informa√ß√µes espec√≠ficas
- Se houver d√∫vidas sobre funcionalidades, explique baseado no contexto da p√°gina atual
- Ofere√ßa exemplos pr√°ticos quando explicar conceitos
- Mantenha respostas concisas mas completas
- Se n√£o souber algo, seja honesto e sugira alternativas
- Lembre-se do contexto anterior da conversa e da p√°gina em que o usu√°rio est√°

üó∫Ô∏è **CONHECIMENTO DAS P√ÅGINAS:**
Voc√™ conhece todas as p√°ginas do sistema e pode orientar o usu√°rio sobre:
- O que cada p√°gina faz
- Como usar suas funcionalidades
- Onde encontrar informa√ß√µes espec√≠ficas
- Dicas e melhores pr√°ticas

üöÄ **EXEMPLOS DE INTERA√á√ÉO:**
- "Ol√°! Sou o assistente do GoMech. Como posso ajudar voc√™ hoje?"
- "Claro! Deixa eu buscar essas informa√ß√µes para voc√™..."
- "Vejo que voc√™ est√° na p√°gina de [X]. Posso te ajudar a [Y]."
- "Posso te mostrar um gr√°fico para facilitar a visualiza√ß√£o. Quer que eu crie?"
- "Sobre [termo]: √© [explica√ß√£o clara e simples]"

Seja sempre √∫til, emp√°tico e focado em resolver o problema do usu√°rio! üéâ
"""

# --- Modelo de Chat ---
model = init_chat_model("gpt-4o-mini", model_provider="openai", api_key=OPENAI_API_KEY, temperature=0.7)

# --- Executor para chamadas s√≠ncronas ---
executor = ThreadPoolExecutor(max_workers=4)

# --- Locks para evitar race conditions ---
conversation_locks: Dict[str, asyncio.Lock] = {}


def get_lock_for_thread(thread_id: str) -> asyncio.Lock:
    if thread_id not in conversation_locks:
        conversation_locks[thread_id] = asyncio.Lock()
    return conversation_locks[thread_id]


# --- Fun√ß√£o s√≠ncrona para chamar o modelo ---
def call_model_sync(state: MessagesState):
    response = model.invoke(state["messages"])
    return {"messages": response}


# --- Grafo LangGraph ---
chat_graph = StateGraph(state_schema=MessagesState)
chat_graph.add_node("model", call_model_sync)
chat_graph.add_edge(START, "model")
checkpointer = MemorySaver()
app_graph = chat_graph.compile(checkpointer=checkpointer)


# --- Fun√ß√µes auxiliares de contexto ---
def _get_route_context(context: Optional[str]) -> str:
    """Extrai informa√ß√µes sobre a rota atual para enriquecer o contexto."""
    if not context:
        return ""
    
    # Normalizar rota (remover IDs e query params)
    normalized = re.sub(r'/\d+', '', context).split('?')[0]
    
    # Primeiro tentar buscar na base de conhecimento detalhada
    route_info = UI_KNOWLEDGE.get("routes", {}).get(normalized)
    if route_info:
        context_text = f"\n\nüìç **P√°gina Atual: {route_info['name']}**"
        context_text += f"\n{route_info['description_full']}"
        context_text += f"\n\n**Principais campos:** {', '.join(route_info['main_fields'][:5])}"
        context_text += f"\n\n**A√ß√µes poss√≠veis:** {', '.join(route_info['possible_actions'][:5])}"
        return context_text
    
    # Fallback para mapeamento simples
    for route, description in ROUTE_MAPPING.items():
        if normalized.startswith(route) and route != "/":
            return f"\n\nüìç **P√°gina Atual:** {description}"
    
    return ""


def _check_glossary_terms(message: str) -> str:
    """Verifica se a mensagem cont√©m termos do gloss√°rio e retorna defini√ß√µes relevantes."""
    message_lower = message.lower()
    found_terms = []
    
    # Buscar no gloss√°rio local
    for term, definition in GLOSSARY.items():
        pattern = r'\b' + re.escape(term.lower()) + r'\b'
        if re.search(pattern, message_lower):
            found_terms.append(f"- **{term.title()}**: {definition}")
    
    # Buscar no gloss√°rio da base de conhecimento
    ui_glossary = UI_KNOWLEDGE.get("glossary", {})
    for term, definition in ui_glossary.items():
        pattern = r'\b' + re.escape(term.lower()) + r'\b'
        if re.search(pattern, message_lower) and term.lower() not in [t.lower() for t in GLOSSARY.keys()]:
            found_terms.append(f"- **{term}**: {definition}")
    
    if found_terms:
        return "\n\nüìö **Termos Relevantes:**\n" + "\n".join(found_terms[:5])  # Limitar a 5 termos
    
    return ""


def _detect_step_by_step_request(message: str, context: Optional[str]) -> Optional[Dict]:
    """
    Detecta se o usu√°rio est√° pedindo um guia passo a passo.
    
    Retorna dict com steps se detectado, sen√£o None.
    """
    message_lower = message.lower()
    
    # Palavras-chave que indicam pedido de tutorial
    tutorial_keywords = [
        "passo a passo", "passo-a-passo", "tutorial", 
        "como fazer", "como fa√ßo", "como criar", "como cadastrar",
        "ensine", "me guie", "me ajude a", "guia",
        "n√£o sei como", "primeiro passo"
    ]
    
    is_tutorial_request = any(keyword in message_lower for keyword in tutorial_keywords)
    
    if not is_tutorial_request:
        return None
    
    # Normalizar contexto
    if context:
        normalized_context = re.sub(r'/\d+', '', context).split('?')[0]
        route_info = UI_KNOWLEDGE.get("routes", {}).get(normalized_context)
        
        if route_info:
            # Identificar qual tipo de guia
            if "criar" in message_lower or "novo" in message_lower or "cadastr" in message_lower:
                if "step_by_step_create" in route_info:
                    return {
                        "type": "step_by_step",
                        "title": f"üìñ Guia: Como criar em {route_info['name']}",
                        "steps": route_info["step_by_step_create"]
                    }
            elif "entrada" in message_lower and "estoque" in message_lower:
                if "step_by_step_entry" in route_info:
                    return {
                        "type": "step_by_step",
                        "title": f"üìñ Guia: Entrada de Estoque",
                        "steps": route_info["step_by_step_entry"]
                    }
            elif "relat√≥rio" in message_lower or "relatorio" in message_lower:
                if "step_by_step_report" in route_info:
                    return {
                        "type": "step_by_step",
                        "title": f"üìñ Guia: Gerar Relat√≥rio",
                        "steps": route_info["step_by_step_report"]
                    }
    
    # Verificar se √© um fluxo comum
    common_flows = UI_KNOWLEDGE.get("common_flows", {})
    if "atendimento" in message_lower or "completo" in message_lower:
        flow = common_flows.get("complete_service")
        if flow:
            return {
                "type": "step_by_step",
                "title": f"üìñ {flow['name']}",
                "steps": flow["steps"]
            }
    elif "estoque" in message_lower and ("gest√£o" in message_lower or "gerenciar" in message_lower):
        flow = common_flows.get("stock_management")
        if flow:
            return {
                "type": "step_by_step",
                "title": f"üìñ {flow['name']}",
                "steps": flow["steps"]
            }
    
    return None


# --- Fun√ß√£o principal de chat ---
async def call_chat(req: ChatRequest, db: Session):
    thread_id = req.thread_id
    user_message = req.message
    user_id = req.user_id

    # Criar conversa se n√£o existir thread_id
    if not thread_id:
        thread_id = str(uuid4())
    conversation = db.query(Conversation).filter_by(thread_id=thread_id).first()
    if not conversation:
        if not user_id:
            raise ValueError("user_id n√£o pode ser nulo")
        conversation = Conversation(thread_id=thread_id, user_id=user_id)
        db.add(conversation)
        try:
            db.commit()
            db.refresh(conversation)
        except Exception as e:
            db.rollback()
            logging.exception("Erro ao criar conversa: %s", e)
            raise

    lock = get_lock_for_thread(thread_id)
    async with lock:
        # --- Detectar se √© pedido de guia passo a passo ---
        step_guide = _detect_step_by_step_request(user_message, req.context)
        if step_guide:
            # Retornar guia diretamente
            steps_text = "\n".join(step_guide["steps"])
            reply = f"{step_guide['title']}\n\n{steps_text}\n\nüí° **Dica:** Siga estes passos em ordem. Se tiver d√∫vidas em algum passo espec√≠fico, √© s√≥ me perguntar!"
            
            # Salvar no hist√≥rico
            try:
                db.add(Message(conversation_id=conversation.id, role="user", content=user_message))
                db.add(Message(conversation_id=conversation.id, role="ai", content=reply))
                db.commit()
            except Exception as e:
                db.rollback()
                logging.exception("Erro ao salvar mensagens de guia: %s", e)
            
            return {
                "reply": reply,
                "thread_id": thread_id,
                "guide_mode": True,
                "steps": step_guide["steps"]
            }
        
        # --- Buscar informa√ß√µes do usu√°rio para personaliza√ß√£o ---
        user = db.query(User).filter_by(id=user_id).first()
        user_context = ""
        if user:
            user_context = f"\n\nüë§ **Contexto do Usu√°rio:**\n- Nome: {user.name}\n- Email: {user.email}\n- Cargo: {user.role}\n"
            if user.organization:
                user_context += f"- Organiza√ß√£o: {user.organization.name}\n"
        
        # --- Enriquecer com contexto da rota ---
        route_context = _get_route_context(req.context)
        
        # --- Verificar termos do gloss√°rio ---
        glossary_context = _check_glossary_terms(user_message)
        
        # --- Reconstruir hist√≥rico com System Prompt enriquecido ---
        db.refresh(conversation)
        enriched_prompt = SYSTEM_PROMPT + user_context + route_context + glossary_context
        messages = [SystemMessage(content=enriched_prompt)]
        
        for msg in sorted(conversation.messages, key=lambda m: m.id):
            if msg.role == "user":
                messages.append(HumanMessage(content=msg.content))
            else:
                messages.append(AIMessage(content=msg.content))
        messages.append(HumanMessage(content=user_message))

        # --- Invocar modelo ---
        loop = asyncio.get_running_loop()
        try:
            result = await asyncio.wait_for(
                loop.run_in_executor(
                    executor,
                    lambda: app_graph.invoke(
                        {"messages": messages},
                        config={"configurable": {"thread_id": thread_id}}
                    )
                ),
                timeout=60.0,
            )
        except asyncio.TimeoutError:
            raise TimeoutError("Tempo esgotado ao consultar modelo")
        except Exception as e:
            logging.exception("Erro ao invocar modelo: %s", e)
            raise

        try:
            reply_message = result["messages"][-1].content
        except Exception:
            logging.exception("Formato inesperado da resposta: %s", result)
            raise RuntimeError("Resposta inesperada do modelo")

        # --- Persistir mensagens no banco ---
        try:
            db.add(Message(conversation_id=conversation.id, role="user", content=user_message))
            db.add(Message(conversation_id=conversation.id, role="ai", content=reply_message))
            db.commit()
        except Exception as e:
            db.rollback()
            logging.exception("Erro ao salvar mensagens: %s", e)
            raise

    return {"reply": reply_message, "thread_id": thread_id}
